require(gridExtra)
require(repr)
options(repr.plot.width=6, repr.plot.height=6)
dists = data.frame(
norm = rnorm(n, mu, sigma),
poiss = rpois(n, mu))
minx = min(min(dists$norm), min(dists$poiss))
maxx = max(max(dists$norm), max(dists$poiss))
bw = (maxx - minx) / 60
p1 = ggplot(dists, aes(norm)) + geom_histogram(binwidth = bw) +
xlab('Frequency of Normal Distribution') +
xlim(minx, maxx)
p2 = ggplot(dists, aes(poiss)) + geom_histogram(binwidth = bw) +
xlab('Frequency of Poisson Distribution')  +
xlim(minx, maxx)
print(grid.arrange(p1, p2, nrow = 2))
#  lapply(dists, summary)
#  summary(dists)
Map(summary,dists)
}
dist.plot(1000000,600)
dist.plot(1000000,300)
dist.plot(1000000,100)
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
dist.plot = function(n, mu, sigma = 10){
require(ggplot2)
require(gridExtra)
require(repr)
options(repr.plot.width=6, repr.plot.height=6)
dists = data.frame(
norm = rnorm(n, mu, sigma),
poiss = rpois(n, mu))
minx = min(min(dists$norm), min(dists$poiss))
maxx = max(max(dists$norm), max(dists$poiss))
bw = (maxx - minx) / 60
p1 = ggplot(dists, aes(norm)) + geom_histogram(binwidth = bw) +
xlab('Frequency of Normal Distribution') +
xlim(minx, maxx)
p2 = ggplot(dists, aes(poiss)) + geom_histogram(binwidth = bw) +
xlab('Frequency of Poisson Distribution')  +
xlim(minx, maxx)
print(grid.arrange(p1, p2, nrow = 2))
#  lapply(dists, summary)
#  summary(dists)
Map(summary,dists)
}
dist.plot(1000000,600)
dist.plot(1000000,300)
dist.plot(1000000,100)
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
dist.plot = function(n, mu, sigma = 10){
require(ggplot2)
require(gridExtra)
require(repr)
options(repr.plot.width=6, repr.plot.height=6)
dists = data.frame(
norm = rnorm(n, mu, sigma),
poiss = rpois(n, mu))
minx = min(min(dists$norm), min(dists$poiss))
maxx = max(max(dists$norm), max(dists$poiss))
bw = (maxx - minx) / 60
p1 = ggplot(dists, aes(norm)) + geom_histogram(binwidth = bw) +
xlab('Frequency of Normal Distribution') +
xlim(minx, maxx)
p2 = ggplot(dists, aes(poiss)) + geom_histogram(binwidth = bw) +
xlab('Frequency of Poisson Distribution')  +
xlim(minx, maxx)
print(grid.arrange(p1, p2, nrow = 2))
#  summary(dists)
#  lapply(dists, summary)
Map(summary,dists)
}
dist.plot(1000000,600)
dist.plot(1000000,300)
dist.plot(1000000,100)
##
## Simulation Example
##
## Class: PCE 350, Data Science Methods
##
## Creator: Steve Elston
##
## Simulation of profits for sandwich shop.
## Shop has 3 types of bread.
## Selling a sandwich = $1 profit
## Out of bread, customer leaves = $0 profit
## Each wasted bread = -$0.20 profit
##
## WARNING. This code has a known bug. It will crash
## for certain combinations of simulation arguments.
sim.demand <- function(n){
bread <- runif(n) # Probabilities of bread choice
ifelse(bread <= 0.5, 'white',
ifelse(bread <= 0.75, 'wheat', 'multi'))
}
demand <- sim.demand(100)
table(demand)
sim.profit <- function(n = 100, sd = 30, bake = 120, test = FALSE){
# number of bread by type
baked <- c(rep('white', times = bake/2),
rep('wheat', times = bake/4),
rep('multi', times = bake/4))
baked <- as.data.frame(table(baked))
names(baked) <- c('bread', 'baked')
arrivals <- 0
while(arrivals < 1) arrivals <- rnorm(1, mean = n, sd = sd)
demand <- sim.demand(arrivals) # demand by bread type
baked$demand <- as.data.frame(table(demand))[,2]
baked$shortfall <- baked$demand - baked$baked
baked$profit <- baked$demand -
ifelse(baked$shortfall < 0, 0.2 * -baked$shortfall,
baked$shortfall )
if(test) print(baked)
data.frame(profit = sum(baked$profit), missed = sum(baked$shortfall))
}
sim.profit(test = TRUE)
plot.profit <- function(df, bins = 50){
require(ggplot2)
require(gridExtra)
bw <- (max(df$profit) - min(df$profit))/(bins - 1)
h1 <- ggplot(df, aes(profit)) + geom_histogram(binwidth = bw) +
ggtitle('Distributions of profits') + xlab('Profits')
bw <- (max(df$missed) - min(df$missed))/(bins - 1)
h2 <- ggplot(df, aes(missed)) + geom_histogram(binwidth = bw) +
ggtitle('Distributions of people missed') + xlab('Missed')
grid.arrange(h1, h2, nrow = 1)
}
dist.profit <- function(reps = 1000, n = 100, sd = 20, bake = 120){
dist <- data.frame(profit = rep(0, times = reps),
missed = rep(0, times = reps))
for(i in 1:reps){
dist[i, ] <- sim.profit(n = n, sd = sd, bake = bake)
}
plot.profit(dist)
data.frame(MeanProfits = round(mean(dist$profit), 0),
stdProfits = round(sqrt(var(dist$profit)), 0),
MeanMissed = round(mean(dist$missed), 0),
stdMissed = round(sqrt(var(dist$missed)), 0) )
}
## How long to simulations take?
system.time(
dist.profit()
)
## Or, get a more detailed, but slower much slower, view
library(microbenchmark)
microbenchmark(
dist.profit(),
times = 20
)
## Test a function
test.demand <- function(){
set.seed(2345)
res <- c("white", "white", "wheat", "white", "white", "white",
"wheat", "multi", "white", "wheat", "white", "white",
"white", "white", "white", "white", "wheat", "white",
"wheat", "white")
demand  <- sim.demand(20)
if(!any(demand != res)) print('sim.demand funciton works!')
else print('ERROR: sim.demand failed')
}
sim.demand = function(lambda, n){
arrivals = rpois(n, lambda)  # Compute realizations of arrivals
demand.mat = matrix(0, n, 3) # Initalize a matrix
i = 1
for (a in arrivals) {
demand.mat[i, ] = t(matrix(table(sim.bread(a)))) # Add one realization to matrix
i = i + 1
}
q
sim.demand = function(lambda, n){
arrivals = rpois(n, lambda)  # Compute realizations of arrivals
demand.mat = matrix(0, n, 3) # Initalize a matrix
i = 1
for (a in arrivals) {
demand.mat[i, ] = t(matrix(table(sim.bread(a)))) # Add one realization to matrix
i = i + 1
}
sim.demand(1,100)
rm(list=ls())
# Clear Console:
cat("\014")
rm(list=ls())
# Clear Console:
cat("\014")
sim.demand = function(lambda, n){
arrivals = rpois(n, lambda)  # Compute realizations of arrivals
demand.mat = matrix(0, n, 3) # Initalize a matrix
i = 1
for (a in arrivals) {
demand.mat[i, ] = t(matrix(table(sim.bread(a)))) # Add one realization to matrix
i = i + 1
}
}
d =  sim.demand(10,100)
install.packages("ggplot2")
rm(list=ls())
# Clear Console:
cat("\014")
g
g
library(ggplot2)
library(MASS)
random_points = mvrnorm(10000, mu=c(0.5,0.5), Sigma=matrix(c(1,0.6,0.6,1), nrow=2))
plot(random_points[,1], random_points[,2], xlim=c(-4,4), ylim=c(-4,4), col=rgb(0,0,0,0.25),
main = 'Draws from a bivariate Normal distribution')
likelihood = function(x,y){
sigma = matrix(c(1,0.6,0.6,1), nrow=2)
mu = c(0.5,0.5)
dist = c(x,y) - mu
value = (1/sqrt(4*pi^2**det(sigma))) * exp((-1/2) * t(dist) %*% ginv(sigma) %*% t(t(dist)) )
return(value)
}
x_chain = 4
y_chain = -4
chain_length = 10000
current_val = likelihood(x_chain,y_chain)
current_val
proposal_sd = .1
accept_count = 0
reject_count = 0
for (n in 1:(chain_length-1)){ # chain length minus 1 because we already have a point (the starting point)
proposed_x = x_chain[n] + rnorm(1, mean=0, sd=proposal_sd)
proposed_y = y_chain[n] + rnorm(1, mean=0, sd=proposal_sd)
proposed_val = likelihood(proposed_x, proposed_y)
# Accept according to probability:
if (runif(1) < (proposed_val/current_val)){
x_chain = c(x_chain, proposed_x)
y_chain = c(y_chain, proposed_y)
current_val = proposed_val
accept_count = accept_count + 1
}else{
x_chain = c(x_chain, x_chain[n])
y_chain = c(y_chain, y_chain[n])
reject_count = reject_count + 1
}
}
plot(x_chain, y_chain, col=rgb(0,0,0,0.25), xlim=c(-4,4), ylim=c(-4,4),
main="MCMC values for a Bivariate Normal", xlab="x", ylab="y")
num_burnin = round(0.1*chain_length)
num_burnin
plot(x_chain[num_burnin:chain_length], y_chain[num_burnin:chain_length],
col=rgb(0,0,0,0.25), xlim=c(-4,4), ylim=c(-4,4),
main="MCMC values for a Bivariate Normal with burn-in", xlab="x", ylab="y")
mcmc_map = c(mean(x_chain), mean(y_chain))
mcmc_map
accept_count/chain_length
reject_count/chain_length
par(mfrow = c(2,1))
plot(x_chain, type="l", main = 'X chain', ylab = 'Value')
plot(y_chain, type="l", main = 'Y chain', ylab = 'Value')
par(mfrow = c(1,1))
par(mfrow = c(2,1))
plot(x_chain[1000:2000], type="l", main = 'X chain', ylab = 'Value')
plot(y_chain[1000:2000], type="l", main = 'Y chain', ylab = 'Value')
par(mfrow = c(1,1))
library(LearnBayes)
minmaxpost <- function(theta, data){
mu <- theta[1]
sigma <- exp(theta[2])
dnorm(data$min, mu, sigma, log=TRUE) +
dnorm(data$max, mu, sigma, log=TRUE) +
(data$n - 2) * log(pnorm(data$max, mu, sigma) -
pnorm(data$min, mu, sigma))
}
data <- list(n=10, min=52, max=84)
fit <- laplace(minmaxpost, c(70, 2), data)
fit
mycontour(minmaxpost, c(45, 95, 1.5, 4), data,
xlab=expression(mu), ylab=expression(paste("log ",sigma)))
mycontour(lbinorm, c(45, 95, 1.5, 4),
list(m=fit$mode, v=fit$var), add=TRUE, col="red",
main = 'Contours of posterior with Normal approx in red')
mcmc.fit <- rwmetrop(minmaxpost,
list(var=fit$v, scale=3),
c(70, 2),
10000,
data)
mcmc.fit$accept  # What is the acceptance ratio
mycontour(minmaxpost, c(45, 95, 1.5, 4), data,
xlab=expression(mu),
ylab=expression(paste("log ",sigma)))
points(mcmc.fit$par)
mu <- mcmc.fit$par[, 1]
sigma <- exp(mcmc.fit$par[, 2])
P.75 <- mu + 0.674 * sigma
plot(density(P.75),
main="Posterior Density of Upper Quartile")
library(LearnBayes)
d <- data.frame(Name=c("Clemente", "Robinson", "Howard", "Johnstone",
"Berry", "Spencer", "Kessinger", "Alvarado", "Santo",
"Swaboda", "Petrocelli", "Rodriguez", "Scott", "Unser",
"Williams", "Campaneris", "Munson", "Alvis"),
Hits=c(18, 17, 16, 15, 14, 14, 13, 12, 11,
11, 10, 10, 10, 10, 10, 9, 8, 7),
At.Bats=45)
laplace.fit <- laplace(betabinexch,
c(0, 0),
d[, c("Hits", "At.Bats")])
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
d <- data.frame(Name=c("Clemente", "Robinson", "Howard", "Johnstone",
"Berry", "Spencer", "Kessinger", "Alvarado", "Santo",
"Swaboda", "Petrocelli", "Rodriguez", "Scott", "Unser",
"Williams", "Campaneris", "Munson", "Alvis"),
Hits=c(18, 17, 16, 15, 14, 14, 13, 12, 11,
11, 10, 10, 10, 10, 10, 9, 8, 7),
At.Bats=45)
laplace.fit <- laplace(betabinexch,
c(0, 0),
d[, c("Hits", "At.Bats")])
laplace.fit
?betabinexch
mcmc.fit <- rwmetrop(betabinexch,
list(var=laplace.fit$var, scale=2),
c(0, 0),
5000,
d[, c("Hits", "At.Bats")])
mcmc.fit$par[1:20]
mcmc.fit$accept
mycontour(betabinexch, c(-1.5, -0.5, 2, 12),
d[, c("Hits", "At.Bats")],
xlab="Logit ETA", ylab="Log K")
with(mcmc.fit, points(par))
eta <- with(mcmc.fit, exp(par[, 1]) / (1 + exp(par[, 1])))
eta[1:20]
K <- exp(mcmc.fit$par[, 2])
K[1:20]
p.estimate <- function(j, eta, K){
yj <- d[j, "Hits"]
nj <- d[j, "At.Bats"]
p.sim <- rbeta(5000, yj + K * eta, nj - yj + K * (1 - eta))
quantile(p.sim, c(0.05, 0.50, 0.95))
}
E <- t(sapply(1:18, p.estimate, eta, K))
rownames(E) <- d[, "Name"]
round(E, 3)
plot(d$Hits / 45, E[, 2], pch=19,
ylim=c(.15, .40),
xlab="Observed AVG", ylab="True Probability",
main="90 Percent Probability Intervals")
for (j in 1:18) lines(d$Hits[j] / 45 * c(1, 1), E[j, c(1, 3)])
abline(a=0, b=1, col="blue")
abline(h=mean(d$Hits) / 45, col="red")
legend("topleft", legend=c("Individual", "Combined"),
lty=1, col=c("blue", "red"))
require(mlbench)
data(HouseVotes84)
require(ggplot2)
Map(function(x, y)
ggplot(HouseVotes84, aes_string(x)) +
geom_bar() +
facet_grid(. ~ Class) +
ggtitle(y),
list('V1', 'V2', 'V3', 'V4', 'V5'),
list(' handicapped-infants',
'water-project-cost-sharing',
'adoption-of-the-budget-resolution',
'physician-fee-freeze',
'el-salvador-aid'))
data(HouseVotes84)
require(e1071)
model <- naiveBayes(Class ~ ., data = HouseVotes84)
party = predict(model, HouseVotes84[1:10,])
nums = predict(model, HouseVotes84[1:10,], type = "raw")
data.frame(party = HouseVotes84$Class[1:10], predicted = party, Democrat = nums[,1], Republican = nums[,2])
pred <- predict(model, HouseVotes84)
table(pred, HouseVotes84$Class)
model <- naiveBayes(Class ~ ., data = HouseVotes84, laplace = 3)
pred <- predict(model, HouseVotes84[,-1])
table(pred, HouseVotes84$Class)
N <- 1000
x <- 1:N
epsilon <- rnorm(N, 0, 1)
y <- x + epsilon
path = 'C:\\Users\\rr657c\\Documents\UW\\Data Science Certificate\\DataScience350\\Lecture9'
full.path = file.path(path, 'example.bug')
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
path = 'C:\\Users\\rr657c\\Documents\\UW\\Data Science Certificate\\DataScience350\\Lecture9'
full.path = file.path(path, 'example.bug')
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
full.path = file.path('C:\\Users\\rr657c\\jags-terminal', 'example.bug')
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
path = 'C:\\Users\\rr657c\\Documents\\UW\\Data Science Certificate\\DataScience350\\Lecture9'
full.path = file.path(path, 'example.bug')
jags.mod.reg <- jags.model('C:\\Users\\rr657c\\jags-terminal',
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
getwd()
path = 'C:\\Users\\rr657c\\Documents\\UW\\Data Science Certificate\\DataScience350\\Lecture9'
full.path = file.path(path, 'example.bug')
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
jags.mod.reg <- jags.model('C:\\Users\\rr657c',
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
jags.mod.reg <- jags.model('C:\\Users\\rr657c\\jags-terminal',
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
path = 'C:\\Users\\rr657c\\Documents\\UW\\Data Science Certificate\\DataScience350\\Lecture9'
full.path = file.path(path, 'example.bug')
jags.mod.reg <- jags.model('C:\\Users\\rr657c\\jags-terminal',
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
jags.mod.reg <- jags.model(full.path,
data = list('x' = x,
'y' = y,
'N' = N),
n.chains = 4,
n.adapt = 1000)
?load
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
require(dplyr)
load("MAJORS1012")
expand.grid()
expand.grid(2,2)
expand.grid(3,3)
expand.grid(0,3)
i <- expand.grid(3,3)
View(i)
View(i)
?readBin
> setwd('C:\\Users\\rr657c\\Documents\\UW\\Data Science Certificate\\DataScience450\\Capstone')
getwd()
> setwd('C://Users//rr657c//Documents//UW//Data Science Certificate//DataScience450//Capstone')
.
?setwd()
> setwd('C:/Users/rr657c/Documents//UW/Data Science Certificate/DataScience450/Capstone')
setwd('C:/Users/rr657c/Documents//UW/Data Science Certificate/DataScience450/Capstone')
setwd('C:\\Users\\rr657c\\Documents\\UW\\Data Science Certificate\\DataScience450\\Capstone')
getwd()
to.read = file("t10k-images-idx3-ubyte", "rb")
to.read = file('t10k-images-idx3-ubyte', 'rb')
?file
to.read <- file("t10k-images-idx3-ubyte", "rb")
getwd()
to.read <- file("C:/Users/rr657c/Documents/UW/Data Science Certificate/DataScience450/Capstone/t10k-images-idx3-ubyte", "rb")
to.read <- file("C:/Users/rr657c/Documents/UW/Data Science Certificate/DataScience450/Capstone/t10k-images-idx3-ubyte", "rb")
to.read <- file("C:/Users/rr657c/Documents/UW/Data Science Certificate/DataScience450/Capstone/t10k-images-idx3-ubyte")
readBin(to.read, integer(), n=1, endian="big")
View(i)
View(i)
to.read <- file("C:/Users/rr657c/Documents/UW/Data Science Certificate/DataScience450/Capstone/t10k-images-idx3-ubyte","rb")
readBin(to.read, integer(), n=1, endian="big")
getwd()
to.read <- file("t10k-images-idx3-ubyte","rb")
to.read <- file("train-images.idx3-ubyte","rb")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=1, endian="big")
readBin(to.read, integer(), n=4, endian="big")
readBin(to.read, integer(), n=4, endian="big")
m = matrix(readBin(to.read,integer(), size=1, n=28*28, endian="big"),28,28)
image(m)
