;
quit()
install.packages("devtools")
install.packages(c('repr', 'IRdisplay', 'crayon', 'pbdZMQ', 'devtools'))
devtools::install_github('IRkernel/IRkernel')
install.packages("devtools")
brew upgrade R
quit()
install.packages("devtools")
quit()
getwd()
install.packages("devtools")
install.packages(c('repr', 'IRdisplay', 'crayon', 'pbdZMQ', 'devtools'))
devtools::install_github('IRkernel/IRkernel')
install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))
devtools::install_github('IRkernel/IRkernel')
install.packages('pbdZMQ')
install.packages('RZMQ')
quit()
install.packages('RCurl')
library(devtools)
install_local('./rzmq')
install_github('IRkernel/repr')
install_github('IRkernel/IRdisplay')
install_github('IRkernel/IRkernel')
IRkernel::installspec()
devtools::install_github('IRkernel/IRkernel')
quit()
quit()
version
quit()
library('learnBayes')
library('LearnBayes')
?LearnBayes
??LearnBayes
require('LearnBayes')
require('learnbayes')
?beta.select
??beta.select
?beta
install.packages("LearnBayes")
beta.par ## The parameters of my Beta distribution
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
## I think the chance of rain is 0.2 with
## with a probability at the 75% point of 0.28
## Compute my Beta prior
beta.par <- beta.select(list(p=0.5, x=0.2), list(p=0.75, x=.28))
beta.par ## The parameters of my Beta distribution
beta.par + c(25, 15)
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
## I think the chance of rain is 0.2 with
## with a probability at the 75% point of 0.28
## Compute my Beta prior
beta.par <- beta.select(list(p=0.5, x=0.2), list(p=0.75, x=.28))
beta.par ## The parameters of my Beta distribution
beta.par + c(25, 15)
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
## I think the chance of rain is 0.2 with
## with a probability at the 75% point of 0.28
## Compute my Beta prior
beta.par <- beta.select(list(p=0.5, x=0.2), list(p=0.75, x=.28))
beta.par ## The parameters of my Beta distribution
beta.par + c(6, 4)
triplot(beta.par, c(6, 4))
beta.par + c(25, 15)
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
## I think the chance of rain is 0.2 with
## with a probability at the 75% point of 0.28
## Compute my Beta prior
beta.par <- beta.select(list(p=0.5, x=0.2), list(p=0.75, x=.28))
beta.par ## The parameters of my Beta distribution
bet.par64 <- beta.par + c(6, 4)
triplot(beta.par, c(6, 4))
betapar2515 <- beta.par + c(25, 15)
triplot(beta.par, c(25, 15))
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
## I think the chance of rain is 0.2 with
## with a probability at the 75% point of 0.28
## Compute my Beta prior
beta.par <- beta.select(list(p=0.5, x=0.2), list(p=0.75, x=.28))
beta.par ## The parameters of my Beta distribution
beta.par64 <- beta.par + c(6, 4)
triplot(beta.par, c(6, 4))
betapar2515 <- beta.par + c(25, 15)
triplot(beta.par, c(25, 15))
beta.par119 <- beta.par + c(11, 9)
triplot(beta.par, c(11, 9))
# Clear objects from Memory
rm(list=ls())
# Clear Console:
cat("\014")
library(LearnBayes)
## I think the chance of rain is 0.2 with
## with a probability at the 75% point of 0.28
## Compute my Beta prior
beta.par <- beta.select(list(p=0.5, x=0.2), list(p=0.75, x=.28))
beta.par ## The parameters of my Beta distribution
beta.par64 <- beta.par + c(6, 4)
triplot(beta.par, c(6, 4))
beta.par119 <- beta.par + c(11, 9)
triplot(beta.par, c(11, 9))
betapar2515 <- beta.par + c(25, 15)
triplot(beta.par, c(25, 15))
options(repr.plot.width=8, repr.plot.height=5)
beta.post.par <- beta.par + c(25, 15)
a <- beta.post.par[1]
b <- beta.post.par[2]
post.sample <- rbeta(10000, beta.post.par[1], beta.post.par[2])
par(mfrow = c(1,2))
quants = quantile(post.sample, c(0.05, 0.95))
breaks = seq(min(post.sample), max(post.sample), length.out = 41)
hist(post.sample, breaks = breaks,
main = 'Distribution of samples \n with 90% HDI',
xlab = 'Sample value',
ylab = 'Density')
abline(v = quants[1], lty = 3, col = 'red', lwd = 3)
abline(v = quants[2], lty = 3, col = 'red', lwd = 3)
qqnorm(post.sample)
par(mfrow = c(1,1))
quants
?rbeta
?hist
?pbetap
?beta.select
pwd
getwd()
setwd('/Users/sayedarizvi/Desktop/DataScience450/Lesson 3')
getwd()
rm(list=ls())
# Clear Console:
cat("\014")
# Set repeatable random seed.
set.seed(123)
#Load the dataset.
read.bank = function(file = 'Bank Data.csv'){
## Read the csv file
bank <- read.csv(file, header = TRUE,
stringsAsFactors = FALSE)
bank[complete.cases(bank), ]
}
# Partition the data into test and training data sets.
PartitionExact = function(dataSet, fractionOfTest = 0.3)
{
#  browser()
random <-runif(nrow(dataSet))
quant <- quantile(random,fractionOfTest)
testFlag <- random <= quant
testingData <- dataSet[testFlag, ]
trainingData <- dataSet[!testFlag, ]
dataSetSplit <- list(trainingData=trainingData, testingData=testingData)
}
# Load and cleanse the csv file.
bank = read.bank()
#Check the structure of the dataset.
str(bank)
#Converting character columns to numeric.
bank$pep <- as.numeric(bank$pep == "YES")
bank$sex <- as.numeric(bank$sex == "MALE")
bank$region[bank$region == "INNER_CITY"] <- 1
bank$region[bank$region == "TOWN"] <- 2
bank$region[bank$region == "RURAL"] <- 3
bank$region[bank$region == "SUBURBAN"] <- 4
bank$region <- as.numeric(bank$region)
bank$married <- as.numeric(bank$married == "YES")
bank$car <- as.numeric(bank$car == "YES")
bank$save_act <- as.numeric(bank$save_act == "YES")
bank$current_act <- as.numeric(bank$current_act == "YES")
bank$mortgage <- as.numeric(bank$mortgage == "YES")
str(bank)
#check the data set header
head(bank)
tail(bank)
lapply(bank, summary)
#Data Exploration
library(reshape2)
library(ggplot2)
ggplot(data = melt(bank), mapping = aes(x = value)) +
geom_histogram(bins = 10) + facet_wrap(~variable, scales = 'free_x')
#Split dataset into test and training data sets.
bankDataset = PartitionExact(bank)
Testbank <- bankDataset$testingData
Trainbank <-bankDataset$trainingData
nrow(Testbank)
head(Testbank)
nrow(Trainbank)
head(Trainbank)
formula <- pep ~ .
formula3 <- pep ~ . - sex - region - current_act
# Classification Tree with rpart
library(rpart)
# grow tree
banktree <- rpart(formula = formula, data = Trainbank,method="class")
banktree3 <- rpart(formula = formula3, data = Trainbank,method="class")
#Plot tree using rpart.plot
library("rpart.plot")
rpart.plot(banktree)
rpart.plot(banktree3)
#Use the model to make the predictions.
PEPPrediction <- as.numeric(predict(banktree, newdata = Testbank, type="class"))
PEPPrediction3 <- as.numeric(predict(banktree3, newdata = Testbank, type="class"))
#Calculate Confusion Matrix for all atributes.
crosstabAll <- table(PEPPrediction, Testbank$pep)
crosstabAll
#Calculate Confusion Matrix for selected features
crosstab3 <- table(PEPPrediction3, Testbank$pep)
crosstab3
#Calculate Specificity (TPR)
Specificity <- function(Table.X)
{
Specificity.X <- (Table.X[2,2])/(Table.X[1,2]+Table.X[2,2])
return(Specificity.X)
}
# Calculate TPR for all attributes
TPRAll <- Specificity(crosstabAll)
TPRAll
# Calculate TPR for selected attributes
TPRA3 <- Specificity(crosstab3)
TPRA3
#calculate FPR from Confusion MAtrix
FPR <- function(Table.X)
{
FPR.X <- (Table.X[1,2])/(Table.X[1,2]+Table.X[2,2])
return(FPR.X)
}
# Calculate FPR for all attributes
FPRAll <- FPR(crosstabAll)
FPRAll
# Calculate FPR for selected attributes
FPR3 <- FPR(crosstab3)
FPR3
#Calculate AUC
library(pROC)
roc_obj_All <- roc(Testbank$pep, PEPPrediction)
auc(roc_obj_All)
roc_obj_3 <- roc(Testbank$pep, PEPPrediction3)
auc(roc_obj_3)
??roc
install.packages('pROC')
?library
rm(list=ls())
# Clear Console:
cat("\014")
# Set repeatable random seed.
set.seed(123)
#Load the dataset.
read.bank = function(file = 'Bank Data.csv'){
## Read the csv file
bank <- read.csv(file, header = TRUE,
stringsAsFactors = FALSE)
bank[complete.cases(bank), ]
}
# Partition the data into test and training data sets.
PartitionExact = function(dataSet, fractionOfTest = 0.3)
{
#  browser()
random <-runif(nrow(dataSet))
quant <- quantile(random,fractionOfTest)
testFlag <- random <= quant
testingData <- dataSet[testFlag, ]
trainingData <- dataSet[!testFlag, ]
dataSetSplit <- list(trainingData=trainingData, testingData=testingData)
}
# Load and cleanse the csv file.
bank = read.bank()
#Check the structure of the dataset.
str(bank)
#Converting character columns to numeric.
bank$pep <- as.numeric(bank$pep == "YES")
bank$sex <- as.numeric(bank$sex == "MALE")
bank$region[bank$region == "INNER_CITY"] <- 1
bank$region[bank$region == "TOWN"] <- 2
bank$region[bank$region == "RURAL"] <- 3
bank$region[bank$region == "SUBURBAN"] <- 4
bank$region <- as.numeric(bank$region)
bank$married <- as.numeric(bank$married == "YES")
bank$car <- as.numeric(bank$car == "YES")
bank$save_act <- as.numeric(bank$save_act == "YES")
bank$current_act <- as.numeric(bank$current_act == "YES")
bank$mortgage <- as.numeric(bank$mortgage == "YES")
str(bank)
#check the data set header
head(bank)
tail(bank)
lapply(bank, summary)
#Data Exploration
library(reshape2)
library(ggplot2)
ggplot(data = melt(bank), mapping = aes(x = value)) +
geom_histogram(bins = 10) + facet_wrap(~variable, scales = 'free_x')
#Split dataset into test and training data sets.
bankDataset = PartitionExact(bank)
Testbank <- bankDataset$testingData
Trainbank <-bankDataset$trainingData
nrow(Testbank)
head(Testbank)
nrow(Trainbank)
head(Trainbank)
formula <- pep ~ .
formula3 <- pep ~ . - sex - region - current_act
# Classification Tree with rpart
library(rpart)
# grow tree
banktree <- rpart(formula = formula, data = Trainbank,method="class")
banktree3 <- rpart(formula = formula3, data = Trainbank,method="class")
#Plot tree using rpart.plot
library("rpart.plot")
rpart.plot(banktree)
rpart.plot(banktree3)
#Use the model to make the predictions.
PEPPrediction <- as.numeric(predict(banktree, newdata = Testbank, type="class"))
PEPPrediction3 <- as.numeric(predict(banktree3, newdata = Testbank, type="class"))
#Calculate Confusion Matrix for all atributes.
crosstabAll <- table(PEPPrediction, Testbank$pep)
crosstabAll
#Calculate Confusion Matrix for selected features
crosstab3 <- table(PEPPrediction3, Testbank$pep)
crosstab3
#Calculate Specificity (TPR)
Specificity <- function(Table.X)
{
Specificity.X <- (Table.X[2,2])/(Table.X[1,2]+Table.X[2,2])
return(Specificity.X)
}
# Calculate TPR for all attributes
TPRAll <- Specificity(crosstabAll)
TPRAll
# Calculate TPR for selected attributes
TPRA3 <- Specificity(crosstab3)
TPRA3
#calculate FPR from Confusion MAtrix
FPR <- function(Table.X)
{
FPR.X <- (Table.X[1,2])/(Table.X[1,2]+Table.X[2,2])
return(FPR.X)
}
# Calculate FPR for all attributes
FPRAll <- FPR(crosstabAll)
FPRAll
# Calculate FPR for selected attributes
FPR3 <- FPR(crosstab3)
FPR3
#Calculate AUC
library(pROC)
roc_obj_All <- roc(Testbank$pep, PEPPrediction)
auc(roc_obj_All)
roc_obj_3 <- roc(Testbank$pep, PEPPrediction3)
auc(roc_obj_3)
?rpart
?prune
rm(list=ls())
# Clear Console:
cat("\014")
# Set repeatable random seed.
set.seed(123)
#Load the dataset.
read.bank = function(file = 'Bank Data.csv'){
## Read the csv file
bank <- read.csv(file, header = TRUE,
stringsAsFactors = FALSE)
bank[complete.cases(bank), ]
}
# Partition the data into test and training data sets.
PartitionExact = function(dataSet, fractionOfTest = 0.3)
{
#  browser()
random <-runif(nrow(dataSet))
quant <- quantile(random,fractionOfTest)
testFlag <- random <= quant
testingData <- dataSet[testFlag, ]
trainingData <- dataSet[!testFlag, ]
dataSetSplit <- list(trainingData=trainingData, testingData=testingData)
}
# Load and cleanse the csv file.
bank = read.bank()
#Check the structure of the dataset.
str(bank)
#Converting character columns to numeric.
bank$pep <- as.numeric(bank$pep == "YES")
bank$sex <- as.numeric(bank$sex == "MALE")
bank$region[bank$region == "INNER_CITY"] <- 1
bank$region[bank$region == "TOWN"] <- 2
bank$region[bank$region == "RURAL"] <- 3
bank$region[bank$region == "SUBURBAN"] <- 4
bank$region <- as.numeric(bank$region)
bank$married <- as.numeric(bank$married == "YES")
bank$car <- as.numeric(bank$car == "YES")
bank$save_act <- as.numeric(bank$save_act == "YES")
bank$current_act <- as.numeric(bank$current_act == "YES")
bank$mortgage <- as.numeric(bank$mortgage == "YES")
str(bank)
#check the data set header
head(bank)
tail(bank)
lapply(bank, summary)
#Data Exploration
library(reshape2)
library(ggplot2)
ggplot(data = melt(bank), mapping = aes(x = value)) +
geom_histogram(bins = 10) + facet_wrap(~variable, scales = 'free_x')
#Split dataset into test and training data sets.
bankDataset = PartitionExact(bank)
Testbank <- bankDataset$testingData
Trainbank <-bankDataset$trainingData
nrow(Testbank)
head(Testbank)
nrow(Trainbank)
head(Trainbank)
formula <- pep ~ .
formula3 <- pep ~ . - sex - region - current_act
# Classification Tree with rpart
library(rpart)
# grow tree
banktree <- rpart(formula = formula, data = Trainbank,method="class")
banktree3 <- rpart(formula = formula3, data = Trainbank,method="class")
#Plot tree using rpart.plot
library("rpart.plot")
rpart.plot(banktree)
install.packages('rpart')
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
rm(list=ls())
# Clear Console:
cat("\014")
# Set repeatable random seed.
set.seed(123)
#Load the dataset.
read.bank = function(file = 'Bank Data.csv'){
## Read the csv file
bank <- read.csv(file, header = TRUE,
stringsAsFactors = FALSE)
bank[complete.cases(bank), ]
}
# Partition the data into test and training data sets.
PartitionExact = function(dataSet, fractionOfTest = 0.3)
{
#  browser()
random <-runif(nrow(dataSet))
quant <- quantile(random,fractionOfTest)
testFlag <- random <= quant
testingData <- dataSet[testFlag, ]
trainingData <- dataSet[!testFlag, ]
dataSetSplit <- list(trainingData=trainingData, testingData=testingData)
}
# Load and cleanse the csv file.
bank = read.bank()
#Check the structure of the dataset.
str(bank)
#Converting character columns to numeric.
bank$pep <- as.numeric(bank$pep == "YES")
bank$sex <- as.numeric(bank$sex == "MALE")
bank$region[bank$region == "INNER_CITY"] <- 1
bank$region[bank$region == "TOWN"] <- 2
bank$region[bank$region == "RURAL"] <- 3
bank$region[bank$region == "SUBURBAN"] <- 4
bank$region <- as.numeric(bank$region)
bank$married <- as.numeric(bank$married == "YES")
bank$car <- as.numeric(bank$car == "YES")
bank$save_act <- as.numeric(bank$save_act == "YES")
bank$current_act <- as.numeric(bank$current_act == "YES")
bank$mortgage <- as.numeric(bank$mortgage == "YES")
str(bank)
#check the data set header
head(bank)
tail(bank)
lapply(bank, summary)
#Data Exploration
library(reshape2)
library(ggplot2)
ggplot(data = melt(bank), mapping = aes(x = value)) +
geom_histogram(bins = 10) + facet_wrap(~variable, scales = 'free_x')
#Split dataset into test and training data sets.
bankDataset = PartitionExact(bank)
Testbank <- bankDataset$testingData
Trainbank <-bankDataset$trainingData
nrow(Testbank)
head(Testbank)
nrow(Trainbank)
head(Trainbank)
formula <- pep ~ .
formula3 <- pep ~ . - sex - region - current_act
# Classification Tree with rpart
library(rpart)
# grow tree
banktree <- rpart(formula = formula, data = Trainbank,method="class")
banktree3 <- rpart(formula = formula3, data = Trainbank,method="class")
#Plot tree using rpart.plot
library("rpart.plot")
rpart.plot(banktree)
